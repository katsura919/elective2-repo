{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09fa9410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cade50aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (768, 9)\n",
      "\n",
      "First 5 rows:\n",
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n",
      "None\n",
      "\n",
      "Basic statistics:\n",
      "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
      "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
      "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
      "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
      "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
      "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
      "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
      "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
      "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
      "\n",
      "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
      "count  768.000000                768.000000  768.000000  768.000000  \n",
      "mean    31.992578                  0.471876   33.240885    0.348958  \n",
      "std      7.884160                  0.331329   11.760232    0.476951  \n",
      "min      0.000000                  0.078000   21.000000    0.000000  \n",
      "25%     27.300000                  0.243750   24.000000    0.000000  \n",
      "50%     32.000000                  0.372500   29.000000    0.000000  \n",
      "75%     36.600000                  0.626250   41.000000    1.000000  \n",
      "max     67.100000                  2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the Pima Indians Diabetes Dataset\n",
    "column_names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', \n",
    "               'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('pima-indians-diabetes.csv', names=column_names)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset info:\")\n",
    "print(df.info())\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cde79d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the dataset:\n",
      "Input Features (8 features):\n",
      "1. Pregnancies\n",
      "2. Glucose\n",
      "3. BloodPressure\n",
      "4. SkinThickness\n",
      "5. Insulin\n",
      "6. BMI\n",
      "7. DiabetesPedigreeFunction\n",
      "8. Age\n",
      "\n",
      "Target Variable: Outcome\n",
      "\n",
      "Total Input Features: 8\n",
      "Target Values Distribution:\n",
      "Outcome\n",
      "0    500\n",
      "1    268\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class Balance:\n",
      "Outcome\n",
      "0    0.651042\n",
      "1    0.348958\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Enlist the column names in your dataset \n",
    "print(\"Column names in the dataset:\")\n",
    "input_features = df.columns[:-1].tolist()  \n",
    "target_column = df.columns[-1]\n",
    "\n",
    "print(\"Input Features (8 features):\")\n",
    "for i, feature in enumerate(input_features, 1):\n",
    "    print(f\"{i}. {feature}\")\n",
    "\n",
    "print(f\"\\nTarget Variable: {target_column}\")\n",
    "print(f\"\\nTotal Input Features: {len(input_features)}\")\n",
    "print(f\"Target Values Distribution:\")\n",
    "print(df['Outcome'].value_counts())\n",
    "print(f\"\\nClass Balance:\")\n",
    "print(df['Outcome'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24dd9c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 4 input features:\n",
      "1. Glucose\n",
      "2. BMI\n",
      "3. Age\n",
      "4. Pregnancies\n",
      "\n",
      "Shape of selected features: (768, 4)\n",
      "\n",
      "First 5 rows of selected features:\n",
      "   Glucose   BMI  Age  Pregnancies\n",
      "0      148  33.6   50            6\n",
      "1       85  26.6   31            1\n",
      "2      183  23.3   32            8\n",
      "3       89  28.1   21            1\n",
      "4      137  43.1   33            0\n",
      "\n",
      "Statistics for selected features:\n",
      "          Glucose         BMI         Age  Pregnancies\n",
      "count  768.000000  768.000000  768.000000   768.000000\n",
      "mean   120.894531   31.992578   33.240885     3.845052\n",
      "std     31.972618    7.884160   11.760232     3.369578\n",
      "min      0.000000    0.000000   21.000000     0.000000\n",
      "25%     99.000000   27.300000   24.000000     1.000000\n",
      "50%    117.000000   32.000000   29.000000     3.000000\n",
      "75%    140.250000   36.600000   41.000000     6.000000\n",
      "max    199.000000   67.100000   81.000000    17.000000\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Extract 4 input features from the dataset\n",
    "selected_features = ['Glucose', 'BMI', 'Age', 'Pregnancies']\n",
    "\n",
    "print(\"Selected 4 input features:\")\n",
    "for i, feature in enumerate(selected_features, 1):\n",
    "    print(f\"{i}. {feature}\")\n",
    "\n",
    "X_selected = df[selected_features]\n",
    "print(f\"\\nShape of selected features: {X_selected.shape}\")\n",
    "print(\"\\nFirst 5 rows of selected features:\")\n",
    "print(X_selected.head())\n",
    "print(\"\\nStatistics for selected features:\")\n",
    "print(X_selected.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5247641e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X and Y matrices established:\n",
      "X shape (Features): (768, 4)\n",
      "Y shape (Target): (768,)\n",
      "\n",
      "X (first 5 rows):\n",
      "[[148.   33.6  50.    6. ]\n",
      " [ 85.   26.6  31.    1. ]\n",
      " [183.   23.3  32.    8. ]\n",
      " [ 89.   28.1  21.    1. ]\n",
      " [137.   43.1  33.    0. ]]\n",
      "\n",
      "Y (first 10 values): [1 0 1 0 1 0 1 0 1 1]\n",
      "\n",
      "Target distribution:\n",
      "Class 0: 500 samples (65.1%)\n",
      "Class 1: 268 samples (34.9%)\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Establish X and Y Matrix\n",
    "\n",
    "X = X_selected.values  \n",
    "Y = df['Outcome'].values  \n",
    "\n",
    "print(\"X and Y matrices established:\")\n",
    "print(f\"X shape (Features): {X.shape}\")\n",
    "print(f\"Y shape (Target): {Y.shape}\")\n",
    "print(f\"\\nX (first 5 rows):\")\n",
    "print(X[:5])\n",
    "print(f\"\\nY (first 10 values): {Y[:10]}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "unique, counts = np.unique(Y, return_counts=True)\n",
    "for val, count in zip(unique, counts):\n",
    "    print(f\"Class {val}: {count} samples ({count/len(Y)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80a71b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split completed (80% train, 20% test)\n",
      "\n",
      "Training set:\n",
      "X_train shape: (614, 4)\n",
      "Y_train shape: (614,)\n",
      "\n",
      "Testing set:\n",
      "X_test shape: (154, 4)\n",
      "Y_test shape: (154,)\n",
      "\n",
      "Class distribution in training set:\n",
      "Class 0: 400 samples (65.1%)\n",
      "Class 1: 214 samples (34.9%)\n",
      "\n",
      "Class distribution in test set:\n",
      "Class 0: 100 samples (64.9%)\n",
      "Class 1: 54 samples (35.1%)\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Perform 80:20 Data Split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "\n",
    "print(\"Data split completed (80% train, 20% test)\")\n",
    "print(f\"\\nTraining set:\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"Y_train shape: {Y_train.shape}\")\n",
    "\n",
    "print(f\"\\nTesting set:\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"Y_test shape: {Y_test.shape}\")\n",
    "\n",
    "# Check class distribution in train and test sets\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "unique_train, counts_train = np.unique(Y_train, return_counts=True)\n",
    "for val, count in zip(unique_train, counts_train):\n",
    "    print(f\"Class {val}: {count} samples ({count/len(Y_train)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nClass distribution in test set:\")\n",
    "unique_test, counts_test = np.unique(Y_test, return_counts=True)\n",
    "for val, count in zip(unique_test, counts_test):\n",
    "    print(f\"Class {val}: {count} samples ({count/len(Y_test)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d81050ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential Neural Network created successfully!\n",
      "\n",
      "Model Architecture:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │            \u001b[38;5;34m60\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m36\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205</span> (820.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m205\u001b[0m (820.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205</span> (820.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m205\u001b[0m (820.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 7: Create a Sequential Neural Network with 4 layers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer (12 neurons, input_dim=4)\n",
    "model.add(Dense(12, input_dim=4, activation='relu'))\n",
    "\n",
    "# 1st Hidden Layer (8 neurons)\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# 2nd Hidden Layer (4 neurons) \n",
    "model.add(Dense(4, activation='relu'))\n",
    "\n",
    "# Output Layer (1 neuron, sigmoid activation for binary classification)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(\"Sequential Neural Network created successfully!\")\n",
    "print(\"\\nModel Architecture:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8701de77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled successfully!\n",
      "\n",
      "Compilation Details:\n",
      "Optimizer: adam\n",
      "Loss function: binary_crossentropy\n",
      "Metrics: accuracy\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Compile the sequential model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"Model compiled successfully!\")\n",
    "print(\"\\nCompilation Details:\")\n",
    "print(f\"Optimizer: adam\")\n",
    "print(f\"Loss function: binary_crossentropy\")\n",
    "print(f\"Metrics: accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd8f4563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Parameters: epochs=50, batch_size=10\n",
      "This may take a moment...\n",
      "Epoch 1/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6064 - loss: 4.9452 - val_accuracy: 0.5779 - val_loss: 0.6348\n",
      "Epoch 2/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6064 - loss: 4.9452 - val_accuracy: 0.5779 - val_loss: 0.6348\n",
      "Epoch 2/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6015 - loss: 0.6756 - val_accuracy: 0.6429 - val_loss: 0.6347\n",
      "Epoch 3/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6015 - loss: 0.6756 - val_accuracy: 0.6429 - val_loss: 0.6347\n",
      "Epoch 3/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6585 - loss: 0.6141 - val_accuracy: 0.5974 - val_loss: 0.6528\n",
      "Epoch 4/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6585 - loss: 0.6141 - val_accuracy: 0.5974 - val_loss: 0.6528\n",
      "Epoch 4/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6569 - loss: 0.6617 - val_accuracy: 0.6494 - val_loss: 0.6320\n",
      "Epoch 5/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6569 - loss: 0.6617 - val_accuracy: 0.6494 - val_loss: 0.6320\n",
      "Epoch 5/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6205 - loss: 0.6552 - val_accuracy: 0.6364 - val_loss: 0.6397\n",
      "Epoch 6/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6205 - loss: 0.6552 - val_accuracy: 0.6364 - val_loss: 0.6397\n",
      "Epoch 6/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6242 - loss: 0.6667 - val_accuracy: 0.6169 - val_loss: 0.6421\n",
      "Epoch 7/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6242 - loss: 0.6667 - val_accuracy: 0.6169 - val_loss: 0.6421\n",
      "Epoch 7/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6437 - loss: 0.6647 - val_accuracy: 0.6494 - val_loss: 0.6306\n",
      "Epoch 8/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6437 - loss: 0.6647 - val_accuracy: 0.6494 - val_loss: 0.6306\n",
      "Epoch 8/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.6974 - loss: 0.6259 - val_accuracy: 0.6429 - val_loss: 0.6411\n",
      "Epoch 9/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.6974 - loss: 0.6259 - val_accuracy: 0.6429 - val_loss: 0.6411\n",
      "Epoch 9/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.6759 - loss: 0.6562 - val_accuracy: 0.6494 - val_loss: 0.6379\n",
      "Epoch 10/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.6759 - loss: 0.6562 - val_accuracy: 0.6494 - val_loss: 0.6379\n",
      "Epoch 10/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.6486 - loss: 0.6531 - val_accuracy: 0.6494 - val_loss: 0.6282\n",
      "Epoch 11/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.6486 - loss: 0.6531 - val_accuracy: 0.6494 - val_loss: 0.6282\n",
      "Epoch 11/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6915 - loss: 0.6371 - val_accuracy: 0.5519 - val_loss: 0.6604\n",
      "Epoch 12/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6915 - loss: 0.6371 - val_accuracy: 0.5519 - val_loss: 0.6604\n",
      "Epoch 12/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - accuracy: 0.6575 - loss: 0.6398 - val_accuracy: 0.6169 - val_loss: 0.6450\n",
      "Epoch 13/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - accuracy: 0.6575 - loss: 0.6398 - val_accuracy: 0.6169 - val_loss: 0.6450\n",
      "Epoch 13/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6293 - loss: 0.6574 - val_accuracy: 0.6494 - val_loss: 0.6242\n",
      "Epoch 14/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6293 - loss: 0.6574 - val_accuracy: 0.6494 - val_loss: 0.6242\n",
      "Epoch 14/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.6058 - loss: 0.6693 - val_accuracy: 0.6494 - val_loss: 0.7014\n",
      "Epoch 15/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.6058 - loss: 0.6693 - val_accuracy: 0.6494 - val_loss: 0.7014\n",
      "Epoch 15/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.6435 - loss: 0.6690 - val_accuracy: 0.6494 - val_loss: 0.6347\n",
      "Epoch 16/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.6435 - loss: 0.6690 - val_accuracy: 0.6494 - val_loss: 0.6347\n",
      "Epoch 16/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.6592 - loss: 0.6500 - val_accuracy: 0.6364 - val_loss: 0.6370\n",
      "Epoch 17/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.6592 - loss: 0.6500 - val_accuracy: 0.6364 - val_loss: 0.6370\n",
      "Epoch 17/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - accuracy: 0.6309 - loss: 0.6601 - val_accuracy: 0.6558 - val_loss: 0.6181\n",
      "Epoch 18/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - accuracy: 0.6309 - loss: 0.6601 - val_accuracy: 0.6558 - val_loss: 0.6181\n",
      "Epoch 18/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.6625 - loss: 0.6359 - val_accuracy: 0.6494 - val_loss: 0.6244\n",
      "Epoch 19/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.6625 - loss: 0.6359 - val_accuracy: 0.6494 - val_loss: 0.6244\n",
      "Epoch 19/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6356 - loss: 0.6640 - val_accuracy: 0.6494 - val_loss: 0.6201\n",
      "Epoch 20/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6356 - loss: 0.6640 - val_accuracy: 0.6494 - val_loss: 0.6201\n",
      "Epoch 20/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.6557 - loss: 0.6363 - val_accuracy: 0.6494 - val_loss: 0.6145\n",
      "Epoch 21/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.6557 - loss: 0.6363 - val_accuracy: 0.6494 - val_loss: 0.6145\n",
      "Epoch 21/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.6453 - loss: 0.6424 - val_accuracy: 0.6494 - val_loss: 0.6112\n",
      "Epoch 22/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.6453 - loss: 0.6424 - val_accuracy: 0.6494 - val_loss: 0.6112\n",
      "Epoch 22/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.6612 - loss: 0.6386 - val_accuracy: 0.6364 - val_loss: 0.6250\n",
      "Epoch 23/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.6612 - loss: 0.6386 - val_accuracy: 0.6364 - val_loss: 0.6250\n",
      "Epoch 23/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.6742 - loss: 0.6253 - val_accuracy: 0.6494 - val_loss: 0.6300\n",
      "Epoch 24/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.6742 - loss: 0.6253 - val_accuracy: 0.6494 - val_loss: 0.6300\n",
      "Epoch 24/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6362 - loss: 0.6482 - val_accuracy: 0.6494 - val_loss: 0.6114\n",
      "Epoch 25/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6362 - loss: 0.6482 - val_accuracy: 0.6494 - val_loss: 0.6114\n",
      "Epoch 25/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6746 - loss: 0.6240 - val_accuracy: 0.6494 - val_loss: 0.6205\n",
      "Epoch 26/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.6591 - loss: 0.6385 - val_accuracy: 0.6623 - val_loss: 0.6348\n",
      "Epoch 27/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.6509 - loss: 0.6369 - val_accuracy: 0.6753 - val_loss: 0.6133\n",
      "Epoch 28/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.6040 - loss: 0.6576 - val_accuracy: 0.6623 - val_loss: 0.6104\n",
      "Epoch 29/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.6442 - loss: 0.6452 - val_accuracy: 0.6364 - val_loss: 0.6090\n",
      "Epoch 30/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6391 - loss: 0.6422 - val_accuracy: 0.6623 - val_loss: 0.6098\n",
      "Epoch 31/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6746 - loss: 0.6240 - val_accuracy: 0.6494 - val_loss: 0.6205\n",
      "Epoch 26/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.6591 - loss: 0.6385 - val_accuracy: 0.6623 - val_loss: 0.6348\n",
      "Epoch 27/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.6509 - loss: 0.6369 - val_accuracy: 0.6753 - val_loss: 0.6133\n",
      "Epoch 28/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.6040 - loss: 0.6576 - val_accuracy: 0.6623 - val_loss: 0.6104\n",
      "Epoch 29/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.6442 - loss: 0.6452 - val_accuracy: 0.6364 - val_loss: 0.6090\n",
      "Epoch 30/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6391 - loss: 0.6422 - val_accuracy: 0.6623 - val_loss: 0.6098\n",
      "Epoch 31/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6705 - loss: 0.6379 - val_accuracy: 0.6494 - val_loss: 0.6211\n",
      "Epoch 32/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6705 - loss: 0.6379 - val_accuracy: 0.6494 - val_loss: 0.6211\n",
      "Epoch 32/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.6573 - loss: 0.6191 - val_accuracy: 0.6429 - val_loss: 0.6036\n",
      "Epoch 33/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.6573 - loss: 0.6191 - val_accuracy: 0.6429 - val_loss: 0.6036\n",
      "Epoch 33/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.6923 - loss: 0.6128 - val_accuracy: 0.6818 - val_loss: 0.6020\n",
      "Epoch 34/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.6923 - loss: 0.6128 - val_accuracy: 0.6818 - val_loss: 0.6020\n",
      "Epoch 34/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.6953 - loss: 0.6186 - val_accuracy: 0.6753 - val_loss: 0.6017\n",
      "Epoch 35/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.6953 - loss: 0.6186 - val_accuracy: 0.6753 - val_loss: 0.6017\n",
      "Epoch 35/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6630 - loss: 0.6231 - val_accuracy: 0.6818 - val_loss: 0.6059\n",
      "Epoch 36/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6630 - loss: 0.6231 - val_accuracy: 0.6818 - val_loss: 0.6059\n",
      "Epoch 36/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.6447 - loss: 0.6395 - val_accuracy: 0.6558 - val_loss: 0.5974\n",
      "Epoch 37/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.6447 - loss: 0.6395 - val_accuracy: 0.6558 - val_loss: 0.5974\n",
      "Epoch 37/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.6456 - loss: 0.6226 - val_accuracy: 0.6558 - val_loss: 0.6073\n",
      "Epoch 38/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.6456 - loss: 0.6226 - val_accuracy: 0.6558 - val_loss: 0.6073\n",
      "Epoch 38/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7029 - loss: 0.6000 - val_accuracy: 0.6494 - val_loss: 0.6319\n",
      "Epoch 39/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7029 - loss: 0.6000 - val_accuracy: 0.6494 - val_loss: 0.6319\n",
      "Epoch 39/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.6926 - loss: 0.6334 - val_accuracy: 0.6494 - val_loss: 0.5940\n",
      "Epoch 40/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.6926 - loss: 0.6334 - val_accuracy: 0.6494 - val_loss: 0.5940\n",
      "Epoch 40/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6767 - loss: 0.6272 - val_accuracy: 0.6753 - val_loss: 0.5941\n",
      "Epoch 41/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6767 - loss: 0.6272 - val_accuracy: 0.6753 - val_loss: 0.5941\n",
      "Epoch 41/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.7206 - loss: 0.5877 - val_accuracy: 0.6558 - val_loss: 0.5961\n",
      "Epoch 42/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.7206 - loss: 0.5877 - val_accuracy: 0.6558 - val_loss: 0.5961\n",
      "Epoch 42/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - accuracy: 0.6497 - loss: 0.6604 - val_accuracy: 0.6494 - val_loss: 0.5913\n",
      "Epoch 43/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - accuracy: 0.6497 - loss: 0.6604 - val_accuracy: 0.6494 - val_loss: 0.5913\n",
      "Epoch 43/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7162 - loss: 0.5881 - val_accuracy: 0.6623 - val_loss: 0.5885\n",
      "Epoch 44/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7162 - loss: 0.5881 - val_accuracy: 0.6623 - val_loss: 0.5885\n",
      "Epoch 44/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.7822 - loss: 0.5639 - val_accuracy: 0.6883 - val_loss: 0.5834\n",
      "Epoch 45/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.7822 - loss: 0.5639 - val_accuracy: 0.6883 - val_loss: 0.5834\n",
      "Epoch 45/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.7528 - loss: 0.5839 - val_accuracy: 0.7078 - val_loss: 0.5856\n",
      "Epoch 46/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.7528 - loss: 0.5839 - val_accuracy: 0.7078 - val_loss: 0.5856\n",
      "Epoch 46/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.6571 - loss: 0.6127 - val_accuracy: 0.6494 - val_loss: 0.6371\n",
      "Epoch 47/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.6571 - loss: 0.6127 - val_accuracy: 0.6494 - val_loss: 0.6371\n",
      "Epoch 47/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.7058 - loss: 0.5982 - val_accuracy: 0.6753 - val_loss: 0.5947\n",
      "Epoch 48/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.7058 - loss: 0.5982 - val_accuracy: 0.6753 - val_loss: 0.5947\n",
      "Epoch 48/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.7082 - loss: 0.5939 - val_accuracy: 0.6883 - val_loss: 0.5824\n",
      "Epoch 49/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.7082 - loss: 0.5939 - val_accuracy: 0.6883 - val_loss: 0.5824\n",
      "Epoch 49/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6745 - loss: 0.6159 - val_accuracy: 0.6948 - val_loss: 0.5805\n",
      "Epoch 50/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6745 - loss: 0.6159 - val_accuracy: 0.6948 - val_loss: 0.5805\n",
      "Epoch 50/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.7179 - loss: 0.5931 - val_accuracy: 0.6688 - val_loss: 0.5773\n",
      "\n",
      "Model training completed!\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.7179 - loss: 0.5931 - val_accuracy: 0.6688 - val_loss: 0.5773\n",
      "\n",
      "Model training completed!\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Fit the model \n",
    "print(\"Training the model...\")\n",
    "print(\"Parameters: epochs=50, batch_size=10\")\n",
    "print(\"This may take a moment...\")\n",
    "\n",
    "history = model.fit(X_train, Y_train, \n",
    "                    epochs=50, \n",
    "                    batch_size=10, \n",
    "                    validation_data=(X_test, Y_test),\n",
    "                    verbose=1)\n",
    "\n",
    "print(\"\\nModel training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0991c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODEL EVALUATION ===\n",
      "\n",
      "Test Results:\n",
      "Test Loss: 0.5773\n",
      "Test Accuracy: 0.6688 (66.88%)\n",
      "\n",
      "Training Results:\n",
      "Training Loss: 0.5777\n",
      "Training Accuracy: 0.7166 (71.66%)\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Evaluate the model displaying the accuracy\n",
    "print(\"=== MODEL EVALUATION ===\")\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print(f\"\\nTest Results:\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "\n",
    "train_loss, train_accuracy = model.evaluate(X_train, Y_train, verbose=0)\n",
    "\n",
    "print(f\"\\nTraining Results:\")\n",
    "print(f\"Training Loss: {train_loss:.4f}\")\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "988f91cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MAKING PREDICTIONS ===\n",
      "Predictions made on 154 test samples\n",
      "\n",
      "First 10 predictions:\n",
      "Sample | Actual | Predicted | Probability | Correct?\n",
      "--------------------------------------------------\n",
      "     1 |      0 |         0 |       0.467 | ✓      \n",
      "     2 |      0 |         0 |       0.068 | ✓      \n",
      "     3 |      0 |         0 |       0.207 | ✓      \n",
      "     4 |      1 |         0 |       0.434 | ✗      \n",
      "     5 |      0 |         0 |       0.467 | ✓      \n",
      "     6 |      0 |         0 |       0.224 | ✓      \n",
      "     7 |      1 |         0 |       0.243 | ✗      \n",
      "     8 |      1 |         0 |       0.467 | ✗      \n",
      "     9 |      0 |         0 |       0.221 | ✓      \n",
      "    10 |      0 |         0 |       0.438 | ✓      \n",
      "\n",
      "=== DETAILED CLASSIFICATION REPORT ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.99      0.78       100\n",
      "           1       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.64       154\n",
      "   macro avg       0.32      0.49      0.39       154\n",
      "weighted avg       0.42      0.64      0.51       154\n",
      "\n",
      "\n",
      "=== CONFUSION MATRIX ===\n",
      "Predicted:  0   1\n",
      "Actual 0: [ 99   1]\n",
      "Actual 1: [ 54   0]\n",
      "\n",
      "=== PREDICTION SUMMARY ===\n",
      "Correct predictions: 99/154\n",
      "Final accuracy: 0.6429 (64.29%)\n"
     ]
    }
   ],
   "source": [
    "# Step 12: Make predictions utilizing the data in the lecture presentation\n",
    "print(\"=== MAKING PREDICTIONS ===\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions_prob = model.predict(X_test, verbose=0)\n",
    "predictions_binary = (predictions_prob > 0.5).astype(int)\n",
    "\n",
    "print(f\"Predictions made on {len(X_test)} test samples\")\n",
    "print(f\"\\nFirst 10 predictions:\")\n",
    "print(\"Sample | Actual | Predicted | Probability | Correct?\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i in range(min(10, len(X_test))):\n",
    "    actual = int(Y_test[i])\n",
    "    predicted = int(predictions_binary[i][0])\n",
    "    probability = float(predictions_prob[i][0])\n",
    "    correct = \"✓\" if actual == predicted else \"✗\"\n",
    "    print(f\"{i+1:6d} | {actual:6d} | {predicted:9d} | {probability:11.3f} | {correct:7s}\")\n",
    "\n",
    "# Calculate additional metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(f\"\\n=== DETAILED CLASSIFICATION REPORT ===\")\n",
    "print(classification_report(Y_test, predictions_binary))\n",
    "\n",
    "print(f\"\\n=== CONFUSION MATRIX ===\")\n",
    "cm = confusion_matrix(Y_test, predictions_binary)\n",
    "print(\"Predicted:  0   1\")\n",
    "print(f\"Actual 0: [{cm[0,0]:3d} {cm[0,1]:3d}]\")\n",
    "print(f\"Actual 1: [{cm[1,0]:3d} {cm[1,1]:3d}]\")\n",
    "\n",
    "print(f\"\\n=== PREDICTION SUMMARY ===\")\n",
    "correct_predictions = np.sum(Y_test == predictions_binary.flatten())\n",
    "total_predictions = len(Y_test)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Correct predictions: {correct_predictions}/{total_predictions}\")\n",
    "print(f\"Final accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
