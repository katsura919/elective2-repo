{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86e008e3",
   "metadata": {},
   "source": [
    "# Lab 4: Machine Learning Ensemble Methods\n",
    "## Activity: Breast Cancer Classification with Ensemble Methods\n",
    "\n",
    "This notebook implements a complete machine learning pipeline with ensemble methods for breast cancer classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02a89eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 569 rows and 33 columns\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the dataset \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "print(f\"Dataset has {len(data)} rows and {len(data.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f865e62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset:\n",
      "Data shape: (569, 33)\n",
      "Number of rows: 569\n",
      "Number of columns: 33\n"
     ]
    }
   ],
   "source": [
    "# 2. Identify the shape of your data \n",
    "print(\"Shape of the dataset:\")\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"Number of rows: {data.shape[0]}\")\n",
    "print(f\"Number of columns: {data.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac97fdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the dataset:\n",
      "\n",
      "All columns:\n",
      " 1. id\n",
      " 2. diagnosis\n",
      " 3. radius_mean\n",
      " 4. texture_mean\n",
      " 5. perimeter_mean\n",
      " 6. area_mean\n",
      " 7. smoothness_mean\n",
      " 8. compactness_mean\n",
      " 9. concavity_mean\n",
      "10. concave points_mean\n",
      "11. symmetry_mean\n",
      "12. fractal_dimension_mean\n",
      "13. radius_se\n",
      "14. texture_se\n",
      "15. perimeter_se\n",
      "16. area_se\n",
      "17. smoothness_se\n",
      "18. compactness_se\n",
      "19. concavity_se\n",
      "20. concave points_se\n",
      "21. symmetry_se\n",
      "22. fractal_dimension_se\n",
      "23. radius_worst\n",
      "24. texture_worst\n",
      "25. perimeter_worst\n",
      "26. area_worst\n",
      "27. smoothness_worst\n",
      "28. compactness_worst\n",
      "29. concavity_worst\n",
      "30. concave points_worst\n",
      "31. symmetry_worst\n",
      "32. fractal_dimension_worst\n",
      "33. Unnamed: 32\n",
      "\n",
      "Total number of columns: 33\n"
     ]
    }
   ],
   "source": [
    "# 3. Enlist the column names in your dataset \n",
    "print(\"Column names in the dataset:\")\n",
    "print(\"\\nAll columns:\")\n",
    "for i, col in enumerate(data.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nTotal number of columns: {len(data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "606354d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature matrix X shape: (569, 30)\n",
      "Target variable y shape: (569,)\n",
      "\n",
      "Target variable unique values: ['M' 'B']\n",
      "Target variable value counts:\n",
      "diagnosis\n",
      "B    357\n",
      "M    212\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_clean = data.drop(['id'], axis=1)\n",
    "if 'Unnamed: 32' in data_clean.columns:\n",
    "    data_clean = data_clean.drop(['Unnamed: 32'], axis=1)\n",
    "\n",
    "\n",
    "X = data_clean.drop(['diagnosis'], axis=1) \n",
    "y = data_clean['diagnosis']  \n",
    "\n",
    "print(f\"\\nFeature matrix X shape: {X.shape}\")\n",
    "print(f\"Target variable y shape: {y.shape}\")\n",
    "print(f\"\\nTarget variable unique values: {y.unique()}\")\n",
    "print(f\"Target variable value counts:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1977c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 70% of the data\n",
      "Testing set: 30% of the data\n"
     ]
    }
   ],
   "source": [
    "# 5. Perform 70/30 Data Split \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.30, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: 70% of the data\")\n",
    "print(f\"Testing set: 30% of the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c606a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set features (X_train): (398, 30)\n",
      "Training set target (y_train): (398,)\n",
      "Testing set features (X_test): (171, 30)\n",
      "Testing set target (y_test): (171,)\n",
      "\n",
      "Class distribution in training set:\n",
      "diagnosis\n",
      "B    250\n",
      "M    148\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution in testing set:\n",
      "diagnosis\n",
      "B    107\n",
      "M     64\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 6. Provide data dimension \n",
    "\n",
    "print(f\"Training set features (X_train): {X_train.shape}\")\n",
    "print(f\"Training set target (y_train): {y_train.shape}\")\n",
    "print(f\"Testing set features (X_test): {X_test.shape}\")\n",
    "print(f\"Testing set target (y_test): {y_test.shape}\")\n",
    "\n",
    "\n",
    "print(\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nClass distribution in testing set:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55812f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining three machine learning models:\n",
      "==================================================\n",
      "✓ Jan: Random Forest Classifier\n",
      "\n",
      "✓ Paul: Support Vector Machine (SVM)\n",
      "\n",
      "✓ Llatuna: Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "# 7. Define the Model \n",
    "print(\"Defining three machine learning models:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Model 1: Jan - Random Forest Classifier\n",
    "Jan = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    random_state=42, \n",
    "    max_depth=10\n",
    ")\n",
    "print(\"✓ Jan: Random Forest Classifier\")\n",
    "\n",
    "# Model 2: Paul - Support Vector Machine\n",
    "Paul = SVC(\n",
    "    kernel='rbf', \n",
    "    random_state=42, \n",
    "    probability=True  \n",
    ")\n",
    "print(\"\\n✓ Paul: Support Vector Machine (SVM)\")\n",
    "\n",
    "# Model 3: Llatuna - Logistic Regression\n",
    "Llatuna = LogisticRegression(\n",
    "    random_state=42, \n",
    "    max_iter=1000\n",
    ")\n",
    "print(\"\\n✓ Llatuna: Logistic Regression\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5179ad31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Jan (Random Forest) trained in 0.175 seconds\n",
      "✓ Paul (SVM) trained in 0.012 seconds\n",
      "✓ Llatuna (Logistic Regression) trained in 0.315 seconds\n"
     ]
    }
   ],
   "source": [
    "# 8. Build the training model \n",
    "import time\n",
    "\n",
    "\n",
    "# Train Jan (Random Forest)\n",
    "start_time = time.time()\n",
    "Jan.fit(X_train, y_train)\n",
    "jan_training_time = time.time() - start_time\n",
    "print(f\"✓ Jan (Random Forest) trained in {jan_training_time:.3f} seconds\")\n",
    "\n",
    "# Train Paul (SVM)\n",
    "start_time = time.time()\n",
    "Paul.fit(X_train, y_train)\n",
    "paul_training_time = time.time() - start_time\n",
    "print(f\"✓ Paul (SVM) trained in {paul_training_time:.3f} seconds\")\n",
    "\n",
    "# Train Llatuna (Logistic Regression)\n",
    "start_time = time.time()\n",
    "Llatuna.fit(X_train, y_train)\n",
    "llatuna_training_time = time.time() - start_time\n",
    "print(f\"✓ Llatuna (Logistic Regression) trained in {llatuna_training_time:.3f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e07167f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction details:\n",
      "• Test samples: 171\n",
      "• Jan predictions shape: (171,)\n",
      "• Paul predictions shape: (171,)\n",
      "• Llatuna predictions shape: (171,)\n",
      "\n",
      "Sample predictions (first 10 samples):\n",
      "Jan:     ['B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'B']\n",
      "Paul:    ['B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B']\n",
      "Llatuna: ['B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B']\n",
      "Actual:  ['B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'B']\n"
     ]
    }
   ],
   "source": [
    "# 9. Perform prediction on test data \n",
    "\n",
    "jan_predictions = Jan.predict(X_test)\n",
    "paul_predictions = Paul.predict(X_test)\n",
    "llatuna_predictions = Llatuna.predict(X_test)\n",
    "\n",
    "\n",
    "print(f\"\\nPrediction details:\")\n",
    "print(f\"• Test samples: {len(X_test)}\")\n",
    "print(f\"• Jan predictions shape: {jan_predictions.shape}\")\n",
    "print(f\"• Paul predictions shape: {paul_predictions.shape}\")\n",
    "print(f\"• Llatuna predictions shape: {llatuna_predictions.shape}\")\n",
    "\n",
    "print(f\"\\nSample predictions (first 10 samples):\")\n",
    "print(f\"Jan:     {jan_predictions[:10]}\")\n",
    "print(f\"Paul:    {paul_predictions[:10]}\")\n",
    "print(f\"Llatuna: {llatuna_predictions[:10]}\")\n",
    "print(f\"Actual:  {y_test.iloc[:10].values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ca3e274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jan (Random Forest) Performance:\n",
      "Accuracy: 0.9649 (96.49%)\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.95      1.00      0.97       107\n",
      "           M       1.00      0.91      0.95        64\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.97      0.95      0.96       171\n",
      "weighted avg       0.97      0.96      0.96       171\n",
      "\n",
      "\n",
      "Paul (SVM) Performance:\n",
      "Accuracy: 0.9006 (90.06%)\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.86      1.00      0.93       107\n",
      "           M       1.00      0.73      0.85        64\n",
      "\n",
      "    accuracy                           0.90       171\n",
      "   macro avg       0.93      0.87      0.89       171\n",
      "weighted avg       0.91      0.90      0.90       171\n",
      "\n",
      "\n",
      "Llatuna (Logistic Regression) Performance:\n",
      "Accuracy: 0.9474 (94.74%)\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.93      0.99      0.96       107\n",
      "           M       0.98      0.88      0.93        64\n",
      "\n",
      "    accuracy                           0.95       171\n",
      "   macro avg       0.96      0.93      0.94       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n",
      "\n",
      "Model Performance Summary:\n",
      "Jan (Random Forest):     0.9649\n",
      "Paul (SVM):              0.9006\n",
      "Llatuna (Log. Reg.):     0.9474\n",
      "Best individual model:   Jan (0.9649)\n"
     ]
    }
   ],
   "source": [
    "# 10. Print Model Performance \n",
    "\n",
    "# Jan (Random Forest) Performance\n",
    "jan_accuracy = accuracy_score(y_test, jan_predictions)\n",
    "print(f\"\\nJan (Random Forest) Performance:\")\n",
    "print(f\"Accuracy: {jan_accuracy:.4f} ({jan_accuracy*100:.2f}%)\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, jan_predictions))\n",
    "\n",
    "# Paul (SVM) Performance\n",
    "paul_accuracy = accuracy_score(y_test, paul_predictions)\n",
    "print(f\"\\nPaul (SVM) Performance:\")\n",
    "print(f\"Accuracy: {paul_accuracy:.4f} ({paul_accuracy*100:.2f}%)\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, paul_predictions))\n",
    "\n",
    "# Llatuna (Logistic Regression) Performance\n",
    "llatuna_accuracy = accuracy_score(y_test, llatuna_predictions)\n",
    "print(f\"\\nLlatuna (Logistic Regression) Performance:\")\n",
    "print(f\"Accuracy: {llatuna_accuracy:.4f} ({llatuna_accuracy*100:.2f}%)\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, llatuna_predictions))\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nModel Performance Summary:\")\n",
    "print(f\"Jan (Random Forest):     {jan_accuracy:.4f}\")\n",
    "print(f\"Paul (SVM):              {paul_accuracy:.4f}\")\n",
    "print(f\"Llatuna (Log. Reg.):     {llatuna_accuracy:.4f}\")\n",
    "\n",
    "# Find best individual model\n",
    "accuracies = {'Jan': jan_accuracy, 'Paul': paul_accuracy, 'Llatuna': llatuna_accuracy}\n",
    "best_model = max(accuracies, key=accuracies.get)\n",
    "print(f\"Best individual model:   {best_model} ({accuracies[best_model]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3db77d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the ensemble model...\n",
      "✓ Ensemble model trained in 0.484 seconds\n",
      "\n",
      "Making predictions with ensemble...\n",
      "✓ Ensemble accuracy: 0.9591 (95.91%)\n"
     ]
    }
   ],
   "source": [
    "# 11. Ensemble Method using VotingClassifier\n",
    "\n",
    "# Create the ensemble model using VotingClassifier\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('Jan', Jan),          \n",
    "        ('Paul', Paul),         \n",
    "        ('Llatuna', Llatuna)    \n",
    "    ],\n",
    "    voting='soft'  \n",
    ")\n",
    "\n",
    "\n",
    "# Train the ensemble model\n",
    "print(\"\\nTraining the ensemble model...\")\n",
    "start_time = time.time()\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "ensemble_training_time = time.time() - start_time\n",
    "print(f\"✓ Ensemble model trained in {ensemble_training_time:.3f} seconds\")\n",
    "\n",
    "# Make predictions with the ensemble\n",
    "print(\"\\nMaking predictions with ensemble...\")\n",
    "ensemble_predictions = ensemble_model.predict(X_test)\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "\n",
    "print(f\"✓ Ensemble accuracy: {ensemble_accuracy:.4f} ({ensemble_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cedbcbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble Model Performance:\n",
      "Accuracy: 0.9591 (95.91%)\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.94      1.00      0.97       107\n",
      "           M       1.00      0.89      0.94        64\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.97      0.95      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n",
      "\n",
      "FINAL PERFORMANCE COMPARISON:\n",
      "============================================================\n",
      "Model                     Accuracy   Percentage  \n",
      "------------------------------------------------------------\n",
      "Jan (Random Forest)       0.9649     96.49       %\n",
      "Paul (SVM)                0.9006     90.06       %\n",
      "Llatuna (Logistic Reg.)   0.9474     94.74       %\n",
      "------------------------------------------------------------\n",
      "ENSEMBLE (Voting)         0.9591     95.91       %\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 12. Ensemble Performance Analysis & Comparison\n",
    "\n",
    "\n",
    "# Ensemble detailed performance\n",
    "print(f\"\\nEnsemble Model Performance:\")\n",
    "print(f\"Accuracy: {ensemble_accuracy:.4f} ({ensemble_accuracy*100:.2f}%)\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, ensemble_predictions))\n",
    "\n",
    "# Complete comparison table\n",
    "print(f\"\\nFINAL PERFORMANCE COMPARISON:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Model':<25} {'Accuracy':<10} {'Percentage':<12}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Jan (Random Forest)':<25} {jan_accuracy:<10.4f} {jan_accuracy*100:<12.2f}%\")\n",
    "print(f\"{'Paul (SVM)':<25} {paul_accuracy:<10.4f} {paul_accuracy*100:<12.2f}%\")\n",
    "print(f\"{'Llatuna (Logistic Reg.)':<25} {llatuna_accuracy:<10.4f} {llatuna_accuracy*100:<12.2f}%\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'ENSEMBLE (Voting)':<25} {ensemble_accuracy:<10.4f} {ensemble_accuracy*100:<12.2f}%\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Analysis\n",
    "all_accuracies = {\n",
    "    'Jan': jan_accuracy,\n",
    "    'Paul': paul_accuracy, \n",
    "    'Llatuna': llatuna_accuracy,\n",
    "    'Ensemble': ensemble_accuracy\n",
    "}\n",
    "\n",
    "best_overall = max(all_accuracies, key=all_accuracies.get)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
