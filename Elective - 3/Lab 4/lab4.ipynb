{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86e008e3",
   "metadata": {},
   "source": [
    "# Lab 4: Machine Learning Ensemble Methods\n",
    "## Activity: Breast Cancer Classification with Ensemble Methods\n",
    "\n",
    "This notebook implements a complete machine learning pipeline with ensemble methods for breast cancer classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a89eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Dataset has 569 rows and 33 columns\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the dataset (5pts)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Dataset has {len(data)} rows and {len(data.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f865e62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset:\n",
      "Data shape: (569, 33)\n",
      "Number of rows: 569\n",
      "Number of columns: 33\n"
     ]
    }
   ],
   "source": [
    "# 2. Identify the shape of your data (5 pts)\n",
    "print(\"Shape of the dataset:\")\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"Number of rows: {data.shape[0]}\")\n",
    "print(f\"Number of columns: {data.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac97fdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the dataset:\n",
      "\n",
      "All columns:\n",
      " 1. id\n",
      " 2. diagnosis\n",
      " 3. radius_mean\n",
      " 4. texture_mean\n",
      " 5. perimeter_mean\n",
      " 6. area_mean\n",
      " 7. smoothness_mean\n",
      " 8. compactness_mean\n",
      " 9. concavity_mean\n",
      "10. concave points_mean\n",
      "11. symmetry_mean\n",
      "12. fractal_dimension_mean\n",
      "13. radius_se\n",
      "14. texture_se\n",
      "15. perimeter_se\n",
      "16. area_se\n",
      "17. smoothness_se\n",
      "18. compactness_se\n",
      "19. concavity_se\n",
      "20. concave points_se\n",
      "21. symmetry_se\n",
      "22. fractal_dimension_se\n",
      "23. radius_worst\n",
      "24. texture_worst\n",
      "25. perimeter_worst\n",
      "26. area_worst\n",
      "27. smoothness_worst\n",
      "28. compactness_worst\n",
      "29. concavity_worst\n",
      "30. concave points_worst\n",
      "31. symmetry_worst\n",
      "32. fractal_dimension_worst\n",
      "33. Unnamed: 32\n",
      "\n",
      "Total number of columns: 33\n"
     ]
    }
   ],
   "source": [
    "# 3. Enlist the column names in your dataset (5pts)\n",
    "print(\"Column names in the dataset:\")\n",
    "print(\"\\nAll columns:\")\n",
    "for i, col in enumerate(data.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nTotal number of columns: {len(data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "606354d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data info before cleaning:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n",
      "None\n",
      "\n",
      "Feature matrix X shape: (569, 30)\n",
      "Target variable y shape: (569,)\n",
      "\n",
      "Target variable unique values: ['M' 'B']\n",
      "Target variable value counts:\n",
      "diagnosis\n",
      "B    357\n",
      "M    212\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 4. Establish X and Y Matrix (5pts)\n",
    "# Clean the data first - remove unnecessary columns\n",
    "print(\"Data info before cleaning:\")\n",
    "print(data.info())\n",
    "\n",
    "# Remove 'id' column and any unnamed columns\n",
    "data_clean = data.drop(['id'], axis=1)\n",
    "if 'Unnamed: 32' in data_clean.columns:\n",
    "    data_clean = data_clean.drop(['Unnamed: 32'], axis=1)\n",
    "\n",
    "# Create feature matrix X and target variable y\n",
    "X = data_clean.drop(['diagnosis'], axis=1)  # Features (all columns except diagnosis)\n",
    "y = data_clean['diagnosis']  # Target variable (diagnosis)\n",
    "\n",
    "print(f\"\\nFeature matrix X shape: {X.shape}\")\n",
    "print(f\"Target variable y shape: {y.shape}\")\n",
    "print(f\"\\nTarget variable unique values: {y.unique()}\")\n",
    "print(f\"Target variable value counts:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1977c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split completed successfully!\n",
      "Training set: 70% of the data\n",
      "Testing set: 30% of the data\n",
      "Random state: 42 (for reproducibility)\n",
      "Stratified split: Yes (maintains class distribution)\n"
     ]
    }
   ],
   "source": [
    "# 5. Perform 70/30 Data Split (5pts)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.30, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Data split completed successfully!\")\n",
    "print(f\"Training set: 70% of the data\")\n",
    "print(f\"Testing set: 30% of the data\")\n",
    "print(f\"Random state: 42 (for reproducibility)\")\n",
    "print(f\"Stratified split: Yes (maintains class distribution)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c606a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Dimensions After Split:\n",
      "========================================\n",
      "Training set features (X_train): (398, 30)\n",
      "Training set target (y_train): (398,)\n",
      "Testing set features (X_test): (171, 30)\n",
      "Testing set target (y_test): (171,)\n",
      "\n",
      "Detailed Information:\n",
      "• Total original samples: 569\n",
      "• Training samples: 398 (69.9%)\n",
      "• Testing samples: 171 (30.1%)\n",
      "• Number of features: 30\n",
      "\n",
      "Class distribution in training set:\n",
      "diagnosis\n",
      "B    250\n",
      "M    148\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution in testing set:\n",
      "diagnosis\n",
      "B    107\n",
      "M     64\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 6. Provide data dimension (train and test) (5pts)\n",
    "print(\"Data Dimensions After Split:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Training set features (X_train): {X_train.shape}\")\n",
    "print(f\"Training set target (y_train): {y_train.shape}\")\n",
    "print(f\"Testing set features (X_test): {X_test.shape}\")\n",
    "print(f\"Testing set target (y_test): {y_test.shape}\")\n",
    "\n",
    "print(\"\\nDetailed Information:\")\n",
    "print(f\"• Total original samples: {len(X)}\")\n",
    "print(f\"• Training samples: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"• Testing samples: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"• Number of features: {X_train.shape[1]}\")\n",
    "\n",
    "print(\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nClass distribution in testing set:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55812f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining three machine learning models:\n",
      "==================================================\n",
      "✓ Jan: Random Forest Classifier\n",
      "  - n_estimators: 100\n",
      "  - max_depth: 10\n",
      "  - random_state: 42\n",
      "\n",
      "✓ Paul: Support Vector Machine (SVM)\n",
      "  - kernel: rbf\n",
      "  - probability: True\n",
      "  - random_state: 42\n",
      "\n",
      "✓ Llatuna: Logistic Regression\n",
      "  - max_iter: 1000\n",
      "  - random_state: 42\n",
      "\n",
      "All three models defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# 7. Define the Model (5pts)\n",
    "# Creating three different models with your specified names\n",
    "print(\"Defining three machine learning models:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Model 1: Jan - Random Forest Classifier\n",
    "Jan = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    random_state=42, \n",
    "    max_depth=10\n",
    ")\n",
    "print(\"✓ Jan: Random Forest Classifier\")\n",
    "print(\"  - n_estimators: 100\")\n",
    "print(\"  - max_depth: 10\")\n",
    "print(\"  - random_state: 42\")\n",
    "\n",
    "# Model 2: Paul - Support Vector Machine\n",
    "Paul = SVC(\n",
    "    kernel='rbf', \n",
    "    random_state=42, \n",
    "    probability=True  # Needed for ensemble voting\n",
    ")\n",
    "print(\"\\n✓ Paul: Support Vector Machine (SVM)\")\n",
    "print(\"  - kernel: rbf\")\n",
    "print(\"  - probability: True\")\n",
    "print(\"  - random_state: 42\")\n",
    "\n",
    "# Model 3: Llatuna - Logistic Regression\n",
    "Llatuna = LogisticRegression(\n",
    "    random_state=42, \n",
    "    max_iter=1000\n",
    ")\n",
    "print(\"\\n✓ Llatuna: Logistic Regression\")\n",
    "print(\"  - max_iter: 1000\")\n",
    "print(\"  - random_state: 42\")\n",
    "\n",
    "print(\"\\nAll three models defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5179ad31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training all three models...\n",
      "========================================\n",
      "✓ Jan (Random Forest) trained in 0.244 seconds\n",
      "✓ Paul (SVM) trained in 0.072 seconds\n",
      "✓ Llatuna (Logistic Regression) trained in 0.654 seconds\n",
      "\n",
      "Total training time: 0.971 seconds\n",
      "All models have been successfully trained!\n"
     ]
    }
   ],
   "source": [
    "# 8. Build the training model (5pts)\n",
    "import time\n",
    "\n",
    "print(\"Training all three models...\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Train Jan (Random Forest)\n",
    "start_time = time.time()\n",
    "Jan.fit(X_train, y_train)\n",
    "jan_training_time = time.time() - start_time\n",
    "print(f\"✓ Jan (Random Forest) trained in {jan_training_time:.3f} seconds\")\n",
    "\n",
    "# Train Paul (SVM)\n",
    "start_time = time.time()\n",
    "Paul.fit(X_train, y_train)\n",
    "paul_training_time = time.time() - start_time\n",
    "print(f\"✓ Paul (SVM) trained in {paul_training_time:.3f} seconds\")\n",
    "\n",
    "# Train Llatuna (Logistic Regression)\n",
    "start_time = time.time()\n",
    "Llatuna.fit(X_train, y_train)\n",
    "llatuna_training_time = time.time() - start_time\n",
    "print(f\"✓ Llatuna (Logistic Regression) trained in {llatuna_training_time:.3f} seconds\")\n",
    "\n",
    "total_training_time = jan_training_time + paul_training_time + llatuna_training_time\n",
    "print(f\"\\nTotal training time: {total_training_time:.3f} seconds\")\n",
    "print(\"All models have been successfully trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e07167f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions on test data...\n",
      "========================================\n",
      "✓ Jan (Random Forest) predictions completed\n",
      "✓ Paul (SVM) predictions completed\n",
      "✓ Llatuna (Logistic Regression) predictions completed\n",
      "\n",
      "Prediction details:\n",
      "• Test samples: 171\n",
      "• Jan predictions shape: (171,)\n",
      "• Paul predictions shape: (171,)\n",
      "• Llatuna predictions shape: (171,)\n",
      "\n",
      "Sample predictions (first 10 samples):\n",
      "Jan:     ['B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'B']\n",
      "Paul:    ['B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B']\n",
      "Llatuna: ['B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B']\n",
      "Actual:  ['B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'B']\n"
     ]
    }
   ],
   "source": [
    "# 9. Perform prediction on test data (5pts)\n",
    "print(\"Making predictions on test data...\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Make predictions with each model\n",
    "jan_predictions = Jan.predict(X_test)\n",
    "paul_predictions = Paul.predict(X_test)\n",
    "llatuna_predictions = Llatuna.predict(X_test)\n",
    "\n",
    "print(\"✓ Jan (Random Forest) predictions completed\")\n",
    "print(\"✓ Paul (SVM) predictions completed\")\n",
    "print(\"✓ Llatuna (Logistic Regression) predictions completed\")\n",
    "\n",
    "print(f\"\\nPrediction details:\")\n",
    "print(f\"• Test samples: {len(X_test)}\")\n",
    "print(f\"• Jan predictions shape: {jan_predictions.shape}\")\n",
    "print(f\"• Paul predictions shape: {paul_predictions.shape}\")\n",
    "print(f\"• Llatuna predictions shape: {llatuna_predictions.shape}\")\n",
    "\n",
    "print(f\"\\nSample predictions (first 10 samples):\")\n",
    "print(f\"Jan:     {jan_predictions[:10]}\")\n",
    "print(f\"Paul:    {paul_predictions[:10]}\")\n",
    "print(f\"Llatuna: {llatuna_predictions[:10]}\")\n",
    "print(f\"Actual:  {y_test.iloc[:10].values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ca3e274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Model Performance\n",
      "==================================================\n",
      "\n",
      "🌟 Jan (Random Forest) Performance:\n",
      "Accuracy: 0.9649 (96.49%)\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.95      1.00      0.97       107\n",
      "           M       1.00      0.91      0.95        64\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.97      0.95      0.96       171\n",
      "weighted avg       0.97      0.96      0.96       171\n",
      "\n",
      "\n",
      "🌟 Paul (SVM) Performance:\n",
      "Accuracy: 0.9006 (90.06%)\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.86      1.00      0.93       107\n",
      "           M       1.00      0.73      0.85        64\n",
      "\n",
      "    accuracy                           0.90       171\n",
      "   macro avg       0.93      0.87      0.89       171\n",
      "weighted avg       0.91      0.90      0.90       171\n",
      "\n",
      "\n",
      "🌟 Llatuna (Logistic Regression) Performance:\n",
      "Accuracy: 0.9474 (94.74%)\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.93      0.99      0.96       107\n",
      "           M       0.98      0.88      0.93        64\n",
      "\n",
      "    accuracy                           0.95       171\n",
      "   macro avg       0.96      0.93      0.94       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n",
      "\n",
      "📊 Model Performance Summary:\n",
      "Jan (Random Forest):     0.9649\n",
      "Paul (SVM):              0.9006\n",
      "Llatuna (Log. Reg.):     0.9474\n",
      "Best individual model:   Jan (0.9649)\n"
     ]
    }
   ],
   "source": [
    "# 10. Print Model Performance (5pts)\n",
    "print(\"Individual Model Performance\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Jan (Random Forest) Performance\n",
    "jan_accuracy = accuracy_score(y_test, jan_predictions)\n",
    "print(f\"\\n🌟 Jan (Random Forest) Performance:\")\n",
    "print(f\"Accuracy: {jan_accuracy:.4f} ({jan_accuracy*100:.2f}%)\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, jan_predictions))\n",
    "\n",
    "# Paul (SVM) Performance\n",
    "paul_accuracy = accuracy_score(y_test, paul_predictions)\n",
    "print(f\"\\n🌟 Paul (SVM) Performance:\")\n",
    "print(f\"Accuracy: {paul_accuracy:.4f} ({paul_accuracy*100:.2f}%)\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, paul_predictions))\n",
    "\n",
    "# Llatuna (Logistic Regression) Performance\n",
    "llatuna_accuracy = accuracy_score(y_test, llatuna_predictions)\n",
    "print(f\"\\n🌟 Llatuna (Logistic Regression) Performance:\")\n",
    "print(f\"Accuracy: {llatuna_accuracy:.4f} ({llatuna_accuracy*100:.2f}%)\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, llatuna_predictions))\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n📊 Model Performance Summary:\")\n",
    "print(f\"Jan (Random Forest):     {jan_accuracy:.4f}\")\n",
    "print(f\"Paul (SVM):              {paul_accuracy:.4f}\")\n",
    "print(f\"Llatuna (Log. Reg.):     {llatuna_accuracy:.4f}\")\n",
    "\n",
    "# Find best individual model\n",
    "accuracies = {'Jan': jan_accuracy, 'Paul': paul_accuracy, 'Llatuna': llatuna_accuracy}\n",
    "best_model = max(accuracies, key=accuracies.get)\n",
    "print(f\"Best individual model:   {best_model} ({accuracies[best_model]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3db77d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Ensemble Method: VotingClassifier\n",
      "==================================================\n",
      "✓ VotingClassifier created with the following models:\n",
      "  - Jan (Random Forest)\n",
      "  - Paul (SVM)\n",
      "  - Llatuna (Logistic Regression)\n",
      "  - Voting method: Soft (probability-based)\n",
      "\n",
      "🔧 Training the ensemble model...\n",
      "✓ Ensemble model trained in 0.518 seconds\n",
      "\n",
      "🎯 Making predictions with ensemble...\n",
      "✓ Ensemble predictions completed\n",
      "✓ Ensemble accuracy: 0.9591 (95.91%)\n"
     ]
    }
   ],
   "source": [
    "# 11. Ensemble Method using VotingClassifier\n",
    "print(\"🚀 Ensemble Method: VotingClassifier\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create the ensemble model using VotingClassifier\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('Jan', Jan),           # Random Forest\n",
    "        ('Paul', Paul),         # SVM\n",
    "        ('Llatuna', Llatuna)    # Logistic Regression\n",
    "    ],\n",
    "    voting='soft'  # Use soft voting (probability-based)\n",
    ")\n",
    "\n",
    "print(\"✓ VotingClassifier created with the following models:\")\n",
    "print(\"  - Jan (Random Forest)\")\n",
    "print(\"  - Paul (SVM)\")  \n",
    "print(\"  - Llatuna (Logistic Regression)\")\n",
    "print(\"  - Voting method: Soft (probability-based)\")\n",
    "\n",
    "# Train the ensemble model\n",
    "print(\"\\n🔧 Training the ensemble model...\")\n",
    "start_time = time.time()\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "ensemble_training_time = time.time() - start_time\n",
    "print(f\"✓ Ensemble model trained in {ensemble_training_time:.3f} seconds\")\n",
    "\n",
    "# Make predictions with the ensemble\n",
    "print(\"\\n🎯 Making predictions with ensemble...\")\n",
    "ensemble_predictions = ensemble_model.predict(X_test)\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "\n",
    "print(f\"✓ Ensemble predictions completed\")\n",
    "print(f\"✓ Ensemble accuracy: {ensemble_accuracy:.4f} ({ensemble_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cedbcbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏆 ENSEMBLE vs INDIVIDUAL MODELS COMPARISON\n",
      "============================================================\n",
      "\n",
      "🔥 Ensemble Model Performance:\n",
      "Accuracy: 0.9591 (95.91%)\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.94      1.00      0.97       107\n",
      "           M       1.00      0.89      0.94        64\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.97      0.95      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n",
      "\n",
      "📊 FINAL PERFORMANCE COMPARISON:\n",
      "============================================================\n",
      "Model                     Accuracy   Percentage  \n",
      "------------------------------------------------------------\n",
      "Jan (Random Forest)       0.9649     96.49       %\n",
      "Paul (SVM)                0.9006     90.06       %\n",
      "Llatuna (Logistic Reg.)   0.9474     94.74       %\n",
      "------------------------------------------------------------\n",
      "🏆 ENSEMBLE (Voting)       0.9591     95.91       %\n",
      "============================================================\n",
      "\n",
      "🎯 ANALYSIS:\n",
      "• Best performing model: Jan (0.9649)\n",
      "• Ensemble accuracy compared to best individual:\n",
      "  0.9591 vs 0.9649\n",
      "  ⚠️ Ensemble decreased by 0.0058 (0.58%)\n",
      "\n",
      "✅ Lab 4 Activity Complete!\n",
      "✅ All models trained and evaluated successfully!\n",
      "✅ Ensemble method implemented with VotingClassifier!\n"
     ]
    }
   ],
   "source": [
    "# 12. Ensemble Performance Analysis & Comparison\n",
    "print(\"\\n🏆 ENSEMBLE vs INDIVIDUAL MODELS COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Ensemble detailed performance\n",
    "print(f\"\\n🔥 Ensemble Model Performance:\")\n",
    "print(f\"Accuracy: {ensemble_accuracy:.4f} ({ensemble_accuracy*100:.2f}%)\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, ensemble_predictions))\n",
    "\n",
    "# Complete comparison table\n",
    "print(f\"\\n📊 FINAL PERFORMANCE COMPARISON:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Model':<25} {'Accuracy':<10} {'Percentage':<12}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Jan (Random Forest)':<25} {jan_accuracy:<10.4f} {jan_accuracy*100:<12.2f}%\")\n",
    "print(f\"{'Paul (SVM)':<25} {paul_accuracy:<10.4f} {paul_accuracy*100:<12.2f}%\")\n",
    "print(f\"{'Llatuna (Logistic Reg.)':<25} {llatuna_accuracy:<10.4f} {llatuna_accuracy*100:<12.2f}%\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'🏆 ENSEMBLE (Voting)':<25} {ensemble_accuracy:<10.4f} {ensemble_accuracy*100:<12.2f}%\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Analysis\n",
    "all_accuracies = {\n",
    "    'Jan': jan_accuracy,\n",
    "    'Paul': paul_accuracy, \n",
    "    'Llatuna': llatuna_accuracy,\n",
    "    'Ensemble': ensemble_accuracy\n",
    "}\n",
    "\n",
    "best_overall = max(all_accuracies, key=all_accuracies.get)\n",
    "print(f\"\\n🎯 ANALYSIS:\")\n",
    "print(f\"• Best performing model: {best_overall} ({all_accuracies[best_overall]:.4f})\")\n",
    "print(f\"• Ensemble accuracy compared to best individual:\")\n",
    "print(f\"  {ensemble_accuracy:.4f} vs {max(jan_accuracy, paul_accuracy, llatuna_accuracy):.4f}\")\n",
    "\n",
    "if ensemble_accuracy > max(jan_accuracy, paul_accuracy, llatuna_accuracy):\n",
    "    improvement = ensemble_accuracy - max(jan_accuracy, paul_accuracy, llatuna_accuracy)\n",
    "    print(f\"  ✅ Ensemble improved by {improvement:.4f} ({improvement*100:.2f}%)\")\n",
    "elif ensemble_accuracy < max(jan_accuracy, paul_accuracy, llatuna_accuracy):\n",
    "    decrease = max(jan_accuracy, paul_accuracy, llatuna_accuracy) - ensemble_accuracy\n",
    "    print(f\"  ⚠️ Ensemble decreased by {decrease:.4f} ({decrease*100:.2f}%)\")\n",
    "else:\n",
    "    print(f\"  ➡️ Ensemble performed equally to best individual model\")\n",
    "\n",
    "print(f\"\\n✅ Lab 4 Activity Complete!\")\n",
    "print(f\"✅ All models trained and evaluated successfully!\")\n",
    "print(f\"✅ Ensemble method implemented with VotingClassifier!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
